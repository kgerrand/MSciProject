{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of Neural Network Model for a New Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load, dump\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "\n",
    "data_path = Path.home()/'OneDrive'/'Kirstin'/'Uni'/'Year4'/'MSciProject'/'data_files'/'saved_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning a neural network model based on \u001b[1mMace Head, Ireland\u001b[0;0m to be applicable at \u001b[1mGosan, South Korea\u001b[0;0m.\n"
     ]
    }
   ],
   "source": [
    "site = 'MHD'\n",
    "site_name = config.site_dict[site]\n",
    "\n",
    "transferred_site = 'GSN'\n",
    "transferred_site_name = config.site_dict[transferred_site]\n",
    "\n",
    "compound = config.compound\n",
    "\n",
    "print(f\"Finetuning a neural network model based on \\033[1m{site_name}\\033[0;0m to be applicable at \\033[1m{transferred_site_name}\\033[0;0m.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Model & Initialising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in model\n",
    "original_model = load(data_path/f'nn_model_{site}.joblib')\n",
    "\n",
    "# loading in training data\n",
    "original_data = pd.read_csv(data_path/f'for_model_{compound}_{site}.csv', parse_dates=['time'])\n",
    "\n",
    "training = original_data[(original_data['time'].dt.year >= 2016) & (original_data['time'].dt.year <= 2018)]\n",
    "training = training.drop(columns=['time'])\n",
    "\n",
    "X_train = training.drop(columns=['flag'])\n",
    "y_train = training['flag']\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "# training model on original site training data\n",
    "original_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>u10_0</th>\n",
       "      <th>u10_1</th>\n",
       "      <th>u10_2</th>\n",
       "      <th>u10_3</th>\n",
       "      <th>u10_4</th>\n",
       "      <th>u10_5</th>\n",
       "      <th>u10_6</th>\n",
       "      <th>u10_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v500_2_past</th>\n",
       "      <th>v500_3_past</th>\n",
       "      <th>v500_4_past</th>\n",
       "      <th>v500_5_past</th>\n",
       "      <th>v500_6_past</th>\n",
       "      <th>v500_7_past</th>\n",
       "      <th>v500_8_past</th>\n",
       "      <th>v500_13_past</th>\n",
       "      <th>v500_14_past</th>\n",
       "      <th>v500_15_past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>2010-07-15 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.690763</td>\n",
       "      <td>-2.413504</td>\n",
       "      <td>-2.079362</td>\n",
       "      <td>-0.467843</td>\n",
       "      <td>-4.827441</td>\n",
       "      <td>0.580885</td>\n",
       "      <td>1.065391</td>\n",
       "      <td>2.663067</td>\n",
       "      <td>...</td>\n",
       "      <td>2.956724</td>\n",
       "      <td>8.791500</td>\n",
       "      <td>3.919943</td>\n",
       "      <td>2.058213</td>\n",
       "      <td>2.199645</td>\n",
       "      <td>2.840251</td>\n",
       "      <td>10.080106</td>\n",
       "      <td>1.347354</td>\n",
       "      <td>4.139025</td>\n",
       "      <td>-2.066434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>2014-09-21 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.385603</td>\n",
       "      <td>1.209845</td>\n",
       "      <td>-3.363423</td>\n",
       "      <td>-1.770733</td>\n",
       "      <td>-3.291179</td>\n",
       "      <td>-2.176362</td>\n",
       "      <td>-2.439491</td>\n",
       "      <td>-5.905895</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.130726</td>\n",
       "      <td>-3.561815</td>\n",
       "      <td>6.215248</td>\n",
       "      <td>13.754383</td>\n",
       "      <td>11.021891</td>\n",
       "      <td>-4.304200</td>\n",
       "      <td>-3.337700</td>\n",
       "      <td>13.703741</td>\n",
       "      <td>-10.480322</td>\n",
       "      <td>-5.818061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2008-03-07 07:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.867782</td>\n",
       "      <td>2.919305</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2.486858</td>\n",
       "      <td>4.190870</td>\n",
       "      <td>-2.035694</td>\n",
       "      <td>-4.202700</td>\n",
       "      <td>-2.256213</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.197463</td>\n",
       "      <td>-5.641761</td>\n",
       "      <td>-0.776241</td>\n",
       "      <td>-0.254065</td>\n",
       "      <td>-1.059376</td>\n",
       "      <td>0.290158</td>\n",
       "      <td>-14.883116</td>\n",
       "      <td>0.587219</td>\n",
       "      <td>6.950803</td>\n",
       "      <td>-0.691532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>2016-01-20 05:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.994573</td>\n",
       "      <td>2.263357</td>\n",
       "      <td>-0.303354</td>\n",
       "      <td>3.497597</td>\n",
       "      <td>5.162735</td>\n",
       "      <td>-1.191066</td>\n",
       "      <td>-3.149698</td>\n",
       "      <td>-3.520934</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.148509</td>\n",
       "      <td>-23.608479</td>\n",
       "      <td>-7.080099</td>\n",
       "      <td>3.852128</td>\n",
       "      <td>-6.611067</td>\n",
       "      <td>-3.859116</td>\n",
       "      <td>-7.364631</td>\n",
       "      <td>-8.681700</td>\n",
       "      <td>-8.706151</td>\n",
       "      <td>-2.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>2015-06-08 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.749644</td>\n",
       "      <td>2.936976</td>\n",
       "      <td>0.297533</td>\n",
       "      <td>-0.440825</td>\n",
       "      <td>1.947626</td>\n",
       "      <td>4.742805</td>\n",
       "      <td>2.025746</td>\n",
       "      <td>-1.811198</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.069165</td>\n",
       "      <td>-4.372243</td>\n",
       "      <td>-0.317615</td>\n",
       "      <td>-2.377529</td>\n",
       "      <td>-1.225105</td>\n",
       "      <td>-1.639202</td>\n",
       "      <td>-2.731714</td>\n",
       "      <td>-1.069158</td>\n",
       "      <td>-0.342285</td>\n",
       "      <td>-0.717616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  flag     u10_0     u10_1     u10_2     u10_3  \\\n",
       "3174 2010-07-15 23:00:00   1.0 -0.690763 -2.413504 -2.079362 -0.467843   \n",
       "7768 2014-09-21 03:00:00   1.0 -5.385603  1.209845 -3.363423 -1.770733   \n",
       "608  2008-03-07 07:00:00   1.0  1.867782  2.919305  0.042532  2.486858   \n",
       "8985 2016-01-20 05:00:00   1.0  1.994573  2.263357 -0.303354  3.497597   \n",
       "8535 2015-06-08 09:00:00   0.0 -2.749644  2.936976  0.297533 -0.440825   \n",
       "\n",
       "         u10_4     u10_5     u10_6     u10_7  ...  v500_2_past  v500_3_past  \\\n",
       "3174 -4.827441  0.580885  1.065391  2.663067  ...     2.956724     8.791500   \n",
       "7768 -3.291179 -2.176362 -2.439491 -5.905895  ...    -4.130726    -3.561815   \n",
       "608   4.190870 -2.035694 -4.202700 -2.256213  ...    -1.197463    -5.641761   \n",
       "8985  5.162735 -1.191066 -3.149698 -3.520934  ...    -9.148509   -23.608479   \n",
       "8535  1.947626  4.742805  2.025746 -1.811198  ...   -14.069165    -4.372243   \n",
       "\n",
       "      v500_4_past  v500_5_past  v500_6_past  v500_7_past  v500_8_past  \\\n",
       "3174     3.919943     2.058213     2.199645     2.840251    10.080106   \n",
       "7768     6.215248    13.754383    11.021891    -4.304200    -3.337700   \n",
       "608     -0.776241    -0.254065    -1.059376     0.290158   -14.883116   \n",
       "8985    -7.080099     3.852128    -6.611067    -3.859116    -7.364631   \n",
       "8535    -0.317615    -2.377529    -1.225105    -1.639202    -2.731714   \n",
       "\n",
       "      v500_13_past  v500_14_past  v500_15_past  \n",
       "3174      1.347354      4.139025     -2.066434  \n",
       "7768     13.703741    -10.480322     -5.818061  \n",
       "608       0.587219      6.950803     -0.691532  \n",
       "8985     -8.681700     -8.706151     -2.002994  \n",
       "8535     -1.069158     -0.342285     -0.717616  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in data\n",
    "data = pd.read_csv(data_path/f'for_model_{compound}_{transferred_site}.csv', parse_dates=['time'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2013-01-01 01:00:00 -> 2014-12-31 23:00:00. Length: 2004\n",
      "Val range: 2015-01-01 01:00:00 -> 2015-12-31 19:00:00. Length: 812\n",
      "Test range: 2016-01-01 21:00:00 -> 2017-12-31 23:00:00. Length: 2012\n"
     ]
    }
   ],
   "source": [
    "# setting up data for finetuning\n",
    "train_data_ft = data[(data['time'].dt.year >= 2013) & (data['time'].dt.year <= 2014)]\n",
    "val_data_ft = data[(data['time'].dt.year >= 2015) & (data['time'].dt.year <= 2015)]\n",
    "test_data_ft = data[(data['time'].dt.year >= 2016) & (data['time'].dt.year <= 2017)]\n",
    "\n",
    "print(f\"Train range: {train_data_ft['time'].min()} -> {train_data_ft['time'].max()}. Length: {len(train_data_ft)}\")\n",
    "print(f\"Val range: {val_data_ft['time'].min()} -> {val_data_ft['time'].max()}. Length: {len(val_data_ft)}\")\n",
    "print(f\"Test range: {test_data_ft['time'].min()} -> {test_data_ft['time'].max()}. Length: {len(test_data_ft)}\")\n",
    "\n",
    "train_data_ft = train_data_ft.drop(columns=['time'])\n",
    "val_data_ft = val_data_ft.drop(columns=['time'])\n",
    "test_data_ft = test_data_ft.drop(columns=['time'])\n",
    "\n",
    "X_train_ft = train_data_ft.drop(columns=['flag'])\n",
    "y_train_ft = train_data_ft['flag']\n",
    "X_val_ft = val_data_ft.drop(columns=['flag'])\n",
    "y_val_ft = val_data_ft['flag']\n",
    "X_test_ft = test_data_ft.drop(columns=['flag'])\n",
    "y_test_ft = test_data_ft['flag']\n",
    "\n",
    "y_train_ft = y_train_ft.dropna()\n",
    "y_val_ft = y_val_ft.dropna()\n",
    "y_test_ft = y_test_ft.dropna()\n",
    "\n",
    "X_train_ft = X_train_ft.loc[y_train_ft.index]\n",
    "X_val_ft = X_val_ft.loc[y_val_ft.index]\n",
    "X_test_ft = X_test_ft.loc[y_test_ft.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2011-01-01 11:00:00 -> 2013-12-30 09:00:00. Length: 3186\n",
      "Val range: 2014-01-03 19:00:00 -> 2014-12-31 23:00:00. Length: 933\n",
      "Test range: 2015-01-01 01:00:00 -> 2017-12-31 23:00:00. Length: 2824\n"
     ]
    }
   ],
   "source": [
    "# setting up data for full retuning\n",
    "train_data = data[(data['time'].dt.year >= 2011) & (data['time'].dt.year <= 2013)]\n",
    "val_data = data[(data['time'].dt.year >= 2014) & (data['time'].dt.year <= 2014)]\n",
    "test_data = data[(data['time'].dt.year >= 2015) & (data['time'].dt.year <= 2017)]\n",
    "\n",
    "print(f\"Train range: {train_data['time'].min()} -> {train_data['time'].max()}. Length: {len(train_data)}\")\n",
    "print(f\"Val range: {val_data['time'].min()} -> {val_data['time'].max()}. Length: {len(val_data)}\")\n",
    "print(f\"Test range: {test_data['time'].min()} -> {test_data['time'].max()}. Length: {len(test_data)}\")\n",
    "\n",
    "train_data = train_data.drop(columns=['time'])\n",
    "val_data = val_data.drop(columns=['time'])\n",
    "test_data = test_data.drop(columns=['time'])\n",
    "\n",
    "X_train = train_data.drop(columns=['flag'])\n",
    "y_train = train_data['flag']\n",
    "X_val = val_data.drop(columns=['flag'])\n",
    "y_val = val_data['flag']\n",
    "X_test = test_data.drop(columns=['flag'])\n",
    "y_test = test_data['flag']\n",
    "\n",
    "y_train = y_train.dropna()\n",
    "y_val = y_val.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "X_train = X_train.loc[y_train.index]\n",
    "X_val = X_val.loc[y_val.index]\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Existing Model on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHD Model Precision: 0.87\n",
      "MHD Model Recall: 0.80\n",
      "MHD Model F1: 0.83\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = original_model.predict(X_val)\n",
    "\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'{site} Model Precision: {precision:.2f}')\n",
    "print(f'{site} Model Recall: {recall:.2f}')\n",
    "print(f'{site} Model F1: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1250, random_state=42, shuffle=False, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1250, random_state=42, shuffle=False, warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1250, random_state=42, shuffle=False, warm_start=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allowing warm start & therefore fine-tuning\n",
    "original_model.warm_start = True\n",
    "\n",
    "# adding more iterations to the model\n",
    "original_model.max_iter += 250\n",
    "\n",
    "# fitting the model to the new data (one years worth)\n",
    "original_model.fit(X_train_ft, y_train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model Precision: 0.94\n",
      "Finetuned Model Recall: 0.21\n",
      "Finetuned Model F1: 0.35\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on validation set\n",
    "y_val_pred = original_model.predict(X_val_ft)\n",
    "\n",
    "precision = precision_score(y_val_ft, y_val_pred)\n",
    "recall = recall_score(y_val_ft, y_val_pred)\n",
    "f1 = f1_score(y_val_ft, y_val_pred)\n",
    "\n",
    "print(f'Finetuned Model Precision: {precision:.2f}')\n",
    "print(f'Finetuned Model Recall: {recall:.2f}')\n",
    "print(f'Finetuned Model F1: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-baselines: 681\n",
      "Number of baselines: 131\n"
     ]
    }
   ],
   "source": [
    "# exploring the distribution of the predictions\n",
    "y_val_pred_int = y_val_pred.astype(int)\n",
    "\n",
    "counts = np.bincount(y_val_pred_int)\n",
    "\n",
    "print(\"Number of non-baselines:\", counts[0])\n",
    "print(\"Number of baselines:\", counts[1])\n",
    "\n",
    "assert counts[0] > 0, \"Model has predicted no non-baselines. This is likely due to the model being overfit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kirst\\\\OneDrive\\\\Kirstin\\\\Uni\\\\Year4\\\\MSciProject\\\\data_files\\\\saved_files\\\\nn_model_GSN_finetuned.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving model\n",
    "dump(original_model, data_path/f'nn_model_{transferred_site}_finetuned.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retuning Model Completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Retuned Model Precision (val): 0.85\n",
      "Full Retuned Model Precision (train): 0.88\n",
      "Full Retuned Model Recall (val): 0.93\n",
      "Full Retuned Model Recall (train): 0.95\n",
      "Full Retuned Model F1 (val): 0.89\n",
      "Full Retuned Model F1 (train): 0.92\n"
     ]
    }
   ],
   "source": [
    "new_model = MLPClassifier(random_state=42,\n",
    "                         max_iter=1000, \n",
    "                         hidden_layer_sizes=(100,), \n",
    "                         shuffle=False,\n",
    "                         activation='relu', \n",
    "                         solver='adam', \n",
    "                         alpha=0.05, \n",
    "                         learning_rate='constant', \n",
    "                         batch_size=100, \n",
    "                         early_stopping=True,\n",
    "                         learning_rate_init=0.001,\n",
    "                         beta_2=0.9,)\n",
    "\n",
    "new_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = new_model.predict(X_val)\n",
    "y_train_pred = new_model.predict(X_train)\n",
    "\n",
    "precision_val = precision_score(y_val, y_val_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_val = recall_score(y_val, y_val_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "print(f'Full Retuned Model Precision (val): {precision_val:.2f}')\n",
    "print(f'Full Retuned Model Precision (train): {precision_train:.2f}')\n",
    "print(f'Full Retuned Model Recall (val): {recall_val:.2f}')\n",
    "print(f'Full Retuned Model Recall (train): {recall_train:.2f}')\n",
    "print(f'Full Retuned Model F1 (val): {f1_val:.2f}')\n",
    "print(f'Full Retuned Model F1 (train): {f1_train:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Retuned Model Precision: 0.86\n",
      "Full Retuned Model Recall: 0.94\n",
      "Full Retuned Model F1: 0.90\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on test set\n",
    "y_test_pred = new_model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Full Retuned Model Precision: {precision:.2f}')\n",
    "print(f'Full Retuned Model Recall: {recall:.2f}')\n",
    "print(f'Full Retuned Model F1: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kirst\\\\OneDrive\\\\Kirstin\\\\Uni\\\\Year4\\\\MSciProject\\\\data_files\\\\saved_files\\\\nn_model_GSN.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving model\n",
    "dump(new_model, data_path/f'nn_model_{transferred_site}.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
