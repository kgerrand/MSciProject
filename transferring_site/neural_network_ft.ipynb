{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of Neural Network Model for a New Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load, dump\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "\n",
    "data_path = Path.home()/'OneDrive'/'Kirstin'/'Uni'/'Year4'/'MSciProject'/'data_files'/'saved_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning a neural network model based on \u001b[1mMace Head, Ireland\u001b[0;0m to be applicable at \u001b[1mGosan, South Korea\u001b[0;0m.\n"
     ]
    }
   ],
   "source": [
    "site = 'MHD'\n",
    "site_name = config.site_dict[site]\n",
    "\n",
    "transferred_site = 'GSN'\n",
    "transferred_site_name = config.site_dict[transferred_site]\n",
    "\n",
    "compound = config.compound\n",
    "\n",
    "print(f\"Finetuning a neural network model based on \\033[1m{site_name}\\033[0;0m to be applicable at \\033[1m{transferred_site_name}\\033[0;0m.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in Model & Initialising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1000, random_state=42, shuffle=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in model\n",
    "original_model = load(data_path/f'nn_model_{site}.joblib')\n",
    "\n",
    "# loading in training data\n",
    "original_data = pd.read_csv(data_path/f'for_model_{compound}_{site}.csv', parse_dates=['time'])\n",
    "\n",
    "training = original_data[(original_data['time'].dt.year >= 2016) & (original_data['time'].dt.year <= 2018)]\n",
    "training = training.drop(columns=['time'])\n",
    "\n",
    "X_train = training.drop(columns=['flag'])\n",
    "y_train = training['flag']\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.loc[y_train.index]\n",
    "\n",
    "# training model on original site training data\n",
    "original_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>u10_0</th>\n",
       "      <th>u10_1</th>\n",
       "      <th>u10_2</th>\n",
       "      <th>u10_3</th>\n",
       "      <th>u10_4</th>\n",
       "      <th>u10_5</th>\n",
       "      <th>u10_6</th>\n",
       "      <th>u10_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v500_7_past</th>\n",
       "      <th>v500_8_past</th>\n",
       "      <th>v500_9_past</th>\n",
       "      <th>v500_10_past</th>\n",
       "      <th>v500_11_past</th>\n",
       "      <th>v500_12_past</th>\n",
       "      <th>v500_13_past</th>\n",
       "      <th>v500_14_past</th>\n",
       "      <th>v500_15_past</th>\n",
       "      <th>v500_16_past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>2011-08-13 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.881042</td>\n",
       "      <td>-1.119953</td>\n",
       "      <td>-0.294964</td>\n",
       "      <td>0.660680</td>\n",
       "      <td>4.564447</td>\n",
       "      <td>2.332123</td>\n",
       "      <td>1.443673</td>\n",
       "      <td>0.984516</td>\n",
       "      <td>...</td>\n",
       "      <td>7.644339</td>\n",
       "      <td>4.067718</td>\n",
       "      <td>-0.310674</td>\n",
       "      <td>-4.241988</td>\n",
       "      <td>-1.066252</td>\n",
       "      <td>4.635225</td>\n",
       "      <td>2.467476</td>\n",
       "      <td>0.331072</td>\n",
       "      <td>-6.825470</td>\n",
       "      <td>-1.123993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>2012-12-18 05:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.048647</td>\n",
       "      <td>3.938265</td>\n",
       "      <td>-4.374005</td>\n",
       "      <td>3.932207</td>\n",
       "      <td>7.548550</td>\n",
       "      <td>2.019376</td>\n",
       "      <td>0.362979</td>\n",
       "      <td>3.888459</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.294484</td>\n",
       "      <td>-16.213642</td>\n",
       "      <td>-17.856808</td>\n",
       "      <td>1.448437</td>\n",
       "      <td>14.860284</td>\n",
       "      <td>0.110616</td>\n",
       "      <td>3.191226</td>\n",
       "      <td>0.177895</td>\n",
       "      <td>-1.784846</td>\n",
       "      <td>-16.182590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9791</th>\n",
       "      <td>2016-12-30 13:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.056820</td>\n",
       "      <td>1.522341</td>\n",
       "      <td>8.544664</td>\n",
       "      <td>0.634604</td>\n",
       "      <td>-5.384145</td>\n",
       "      <td>-4.480169</td>\n",
       "      <td>0.148513</td>\n",
       "      <td>-2.798340</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.742884</td>\n",
       "      <td>0.673661</td>\n",
       "      <td>-8.972642</td>\n",
       "      <td>-16.933610</td>\n",
       "      <td>-1.572505</td>\n",
       "      <td>-1.270082</td>\n",
       "      <td>4.801098</td>\n",
       "      <td>3.920806</td>\n",
       "      <td>0.134127</td>\n",
       "      <td>-1.853630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2008-01-23 17:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.752649</td>\n",
       "      <td>4.386697</td>\n",
       "      <td>3.511680</td>\n",
       "      <td>4.954211</td>\n",
       "      <td>9.705658</td>\n",
       "      <td>3.229110</td>\n",
       "      <td>-0.050717</td>\n",
       "      <td>2.818316</td>\n",
       "      <td>...</td>\n",
       "      <td>8.931255</td>\n",
       "      <td>6.070133</td>\n",
       "      <td>5.884708</td>\n",
       "      <td>-6.165054</td>\n",
       "      <td>-3.736271</td>\n",
       "      <td>-7.964544</td>\n",
       "      <td>-0.486044</td>\n",
       "      <td>1.930249</td>\n",
       "      <td>3.528942</td>\n",
       "      <td>2.904453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10709</th>\n",
       "      <td>2017-11-11 09:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.853929</td>\n",
       "      <td>1.777461</td>\n",
       "      <td>0.458568</td>\n",
       "      <td>0.083797</td>\n",
       "      <td>2.077065</td>\n",
       "      <td>-3.067900</td>\n",
       "      <td>-2.061937</td>\n",
       "      <td>-2.960747</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.262307</td>\n",
       "      <td>-3.014819</td>\n",
       "      <td>-14.346397</td>\n",
       "      <td>-6.866427</td>\n",
       "      <td>2.280358</td>\n",
       "      <td>2.266561</td>\n",
       "      <td>7.707224</td>\n",
       "      <td>2.739390</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>1.126506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  flag     u10_0     u10_1     u10_2     u10_3  \\\n",
       "4701  2011-08-13 03:00:00   1.0 -0.881042 -1.119953 -0.294964  0.660680   \n",
       "6052  2012-12-18 05:00:00   1.0  4.048647  3.938265 -4.374005  3.932207   \n",
       "9791  2016-12-30 13:00:00   1.0  1.056820  1.522341  8.544664  0.634604   \n",
       "371   2008-01-23 17:00:00   1.0  5.752649  4.386697  3.511680  4.954211   \n",
       "10709 2017-11-11 09:00:00   1.0 -0.853929  1.777461  0.458568  0.083797   \n",
       "\n",
       "          u10_4     u10_5     u10_6     u10_7  ...  v500_7_past  v500_8_past  \\\n",
       "4701   4.564447  2.332123  1.443673  0.984516  ...     7.644339     4.067718   \n",
       "6052   7.548550  2.019376  0.362979  3.888459  ...    -1.294484   -16.213642   \n",
       "9791  -5.384145 -4.480169  0.148513 -2.798340  ...    -1.742884     0.673661   \n",
       "371    9.705658  3.229110 -0.050717  2.818316  ...     8.931255     6.070133   \n",
       "10709  2.077065 -3.067900 -2.061937 -2.960747  ...    -2.262307    -3.014819   \n",
       "\n",
       "       v500_9_past  v500_10_past  v500_11_past  v500_12_past  v500_13_past  \\\n",
       "4701     -0.310674     -4.241988     -1.066252      4.635225      2.467476   \n",
       "6052    -17.856808      1.448437     14.860284      0.110616      3.191226   \n",
       "9791     -8.972642    -16.933610     -1.572505     -1.270082      4.801098   \n",
       "371       5.884708     -6.165054     -3.736271     -7.964544     -0.486044   \n",
       "10709   -14.346397     -6.866427      2.280358      2.266561      7.707224   \n",
       "\n",
       "       v500_14_past  v500_15_past  v500_16_past  \n",
       "4701       0.331072     -6.825470     -1.123993  \n",
       "6052       0.177895     -1.784846    -16.182590  \n",
       "9791       3.920806      0.134127     -1.853630  \n",
       "371        1.930249      3.528942      2.904453  \n",
       "10709      2.739390      0.005263      1.126506  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in data\n",
    "data = pd.read_csv(data_path/f'for_model_{compound}_{transferred_site}.csv', parse_dates=['time'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2011-01-01 11:00:00 -> 2014-12-31 23:00:00. Length: 4119\n",
      "Val range: 2015-01-01 01:00:00 -> 2015-12-31 19:00:00. Length: 812\n",
      "Test range: 2016-01-01 21:00:00 -> 2017-12-31 23:00:00. Length: 2012\n"
     ]
    }
   ],
   "source": [
    "# setting up data for finetuning\n",
    "train_data_ft = data[(data['time'].dt.year >= 2011) & (data['time'].dt.year <= 2014)]\n",
    "val_data_ft = data[(data['time'].dt.year >= 2015) & (data['time'].dt.year <= 2015)]\n",
    "test_data_ft = data[(data['time'].dt.year >= 2016) & (data['time'].dt.year <= 2017)]\n",
    "\n",
    "print(f\"Train range: {train_data_ft['time'].min()} -> {train_data_ft['time'].max()}. Length: {len(train_data_ft)}\")\n",
    "print(f\"Val range: {val_data_ft['time'].min()} -> {val_data_ft['time'].max()}. Length: {len(val_data_ft)}\")\n",
    "print(f\"Test range: {test_data_ft['time'].min()} -> {test_data_ft['time'].max()}. Length: {len(test_data_ft)}\")\n",
    "\n",
    "train_data_ft = train_data_ft.drop(columns=['time'])\n",
    "val_data_ft = val_data_ft.drop(columns=['time'])\n",
    "test_data_ft = test_data_ft.drop(columns=['time'])\n",
    "\n",
    "X_train_ft = train_data_ft.drop(columns=['flag'])\n",
    "y_train_ft = train_data_ft['flag']\n",
    "X_val_ft = val_data_ft.drop(columns=['flag'])\n",
    "y_val_ft = val_data_ft['flag']\n",
    "X_test_ft = test_data_ft.drop(columns=['flag'])\n",
    "y_test_ft = test_data_ft['flag']\n",
    "\n",
    "y_train_ft = y_train_ft.dropna()\n",
    "y_val_ft = y_val_ft.dropna()\n",
    "y_test_ft = y_test_ft.dropna()\n",
    "\n",
    "X_train_ft = X_train_ft.loc[y_train_ft.index]\n",
    "X_val_ft = X_val_ft.loc[y_val_ft.index]\n",
    "X_test_ft = X_test_ft.loc[y_test_ft.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2009-01-01 01:00:00 -> 2013-12-30 09:00:00. Length: 5763\n",
      "Val range: 2014-01-03 19:00:00 -> 2014-12-31 23:00:00. Length: 933\n",
      "Test range: 2015-01-01 01:00:00 -> 2017-12-31 23:00:00. Length: 2824\n"
     ]
    }
   ],
   "source": [
    "# setting up data for full retuning\n",
    "train_data = data[(data['time'].dt.year >= 2009) & (data['time'].dt.year <= 2013)]\n",
    "val_data = data[(data['time'].dt.year >= 2014) & (data['time'].dt.year <= 2014)]\n",
    "test_data = data[(data['time'].dt.year >= 2015) & (data['time'].dt.year <= 2017)]\n",
    "\n",
    "print(f\"Train range: {train_data['time'].min()} -> {train_data['time'].max()}. Length: {len(train_data)}\")\n",
    "print(f\"Val range: {val_data['time'].min()} -> {val_data['time'].max()}. Length: {len(val_data)}\")\n",
    "print(f\"Test range: {test_data['time'].min()} -> {test_data['time'].max()}. Length: {len(test_data)}\")\n",
    "\n",
    "train_data = train_data.drop(columns=['time'])\n",
    "val_data = val_data.drop(columns=['time'])\n",
    "test_data = test_data.drop(columns=['time'])\n",
    "\n",
    "X_train = train_data.drop(columns=['flag'])\n",
    "y_train = train_data['flag']\n",
    "X_val = val_data.drop(columns=['flag'])\n",
    "y_val = val_data['flag']\n",
    "X_test = test_data.drop(columns=['flag'])\n",
    "y_test = test_data['flag']\n",
    "\n",
    "y_train = y_train.dropna()\n",
    "y_val = y_val.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "X_train = X_train.loc[y_train.index]\n",
    "X_val = X_val.loc[y_val.index]\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Existing Model on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHD Model Precision: 0.81\n",
      "MHD Model Recall: 0.89\n",
      "MHD Model F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = original_model.predict(X_val)\n",
    "\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'{site} Model Precision: {precision:.2f}')\n",
    "print(f'{site} Model Recall: {recall:.2f}')\n",
    "print(f'{site} Model F1: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1500, random_state=42, shuffle=False, warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1500, random_state=42, shuffle=False, warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.05, batch_size=100, beta_2=0.9, early_stopping=True,\n",
       "              max_iter=1500, random_state=42, shuffle=False, warm_start=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allowing warm start & therefore fine-tuning\n",
    "original_model.warm_start = True\n",
    "\n",
    "# adding more iterations to the model\n",
    "original_model.max_iter += 500\n",
    "\n",
    "# fitting the model to the new data (one years worth)\n",
    "original_model.fit(X_train_ft, y_train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model Precision: 0.800\n",
      "Finetuned Model Recall: 0.922\n",
      "Finetuned Model F1: 0.856\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on validation set\n",
    "y_val_pred = original_model.predict(X_val_ft)\n",
    "\n",
    "precision = precision_score(y_val_ft, y_val_pred)\n",
    "recall = recall_score(y_val_ft, y_val_pred)\n",
    "f1 = f1_score(y_val_ft, y_val_pred)\n",
    "\n",
    "print(f'Finetuned Model Precision: {precision:.3f}')\n",
    "print(f'Finetuned Model Recall: {recall:.3f}')\n",
    "print(f'Finetuned Model F1: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model Precision: 0.848\n",
      "Finetuned Model Recall: 0.897\n",
      "Finetuned Model F1: 0.872\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on test set\n",
    "y_test_pred = original_model.predict(X_test_ft)\n",
    "\n",
    "precision = precision_score(y_test_ft, y_test_pred)\n",
    "recall = recall_score(y_test_ft, y_test_pred)\n",
    "f1 = f1_score(y_test_ft, y_test_pred)\n",
    "\n",
    "print(f'Finetuned Model Precision: {precision:.3f}')\n",
    "print(f'Finetuned Model Recall: {recall:.3f}')\n",
    "print(f'Finetuned Model F1: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-baselines: 148\n",
      "Number of baselines: 664\n"
     ]
    }
   ],
   "source": [
    "# exploring the distribution of the predictions - avoiding overfitting\n",
    "y_val_pred_int = y_val_pred.astype(int)\n",
    "\n",
    "counts = np.bincount(y_val_pred_int)\n",
    "\n",
    "print(\"Number of non-baselines:\", counts[0])\n",
    "print(\"Number of baselines:\", counts[1])\n",
    "\n",
    "assert counts[0] > 0, \"Model has predicted no non-baselines. This is likely due to the model being overfit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kirst\\\\OneDrive\\\\Kirstin\\\\Uni\\\\Year4\\\\MSciProject\\\\data_files\\\\saved_files\\\\nn_model_GSN_finetuned.joblib']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving model\n",
    "dump(original_model, data_path/f'nn_model_{transferred_site}_finetuned.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retuning Model Completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set = 0.856\n",
      "Precision on Validation Set = 0.794\n",
      "Recall on Training Set = 0.984\n",
      "Recall on Validation Set = 0.993\n",
      "F1 Score on Training Set = 0.916\n",
      "F1 Score on Validation Set = 0.882\n"
     ]
    }
   ],
   "source": [
    "new_model = MLPClassifier(random_state=42,\n",
    "                         max_iter=1000, \n",
    "                         hidden_layer_sizes=(100,), \n",
    "                         shuffle=False,\n",
    "                         activation='relu', \n",
    "                         solver='adam', \n",
    "                         alpha=0.05, \n",
    "                         learning_rate='constant', \n",
    "                         batch_size=100, \n",
    "                         early_stopping=True,\n",
    "                         learning_rate_init=0.001,\n",
    "                         beta_2=0.9,)\n",
    "\n",
    "new_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = new_model.predict(X_val)\n",
    "y_train_pred = new_model.predict(X_train)\n",
    "\n",
    "precision_val = precision_score(y_val, y_val_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_val = recall_score(y_val, y_val_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_val = f1_score(y_val, y_val_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Precision on Training Set = {precision_train:.3f}\")\n",
    "print(f\"Precision on Validation Set = {precision_val:.3f}\")\n",
    "print(f\"Recall on Training Set = {recall_train:.3f}\")\n",
    "print(f\"Recall on Validation Set = {recall_val:.3f}\")\n",
    "print(f\"F1 Score on Training Set = {f1_train:.3f}\")\n",
    "print(f\"F1 Score on Validation Set = {f1_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.799\n",
      "Test Recall: 0.985\n",
      "Test F1 Score: 0.882\n"
     ]
    }
   ],
   "source": [
    "# evaluating model on test set\n",
    "y_test_pred = new_model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Precision: {precision:.3f}\")\n",
    "print(f\"Test Recall: {recall:.3f}\")\n",
    "print(f\"Test F1 Score: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
