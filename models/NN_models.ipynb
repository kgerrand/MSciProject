{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "data_path = Path.home()/'OneDrive'/'Kirstin'/'Uni'/'Year4'/'MSciProject'/'data_files'/'saved_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising WandB\n",
    "import wandb, os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"e84d2e19bd2cc42ec6e5d232cd0b6f0fe41f2189\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"NN_models.ipynb\"\n",
    "\n",
    "\n",
    "# Syntax for using WandB:\n",
    "\n",
    "# wandb.init(project=\"MSciProject\", name=\"name\", notebook=\"your-notebook-name\")\n",
    "# code here\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>u10_0</th>\n",
       "      <th>u10_1</th>\n",
       "      <th>u10_2</th>\n",
       "      <th>u10_3</th>\n",
       "      <th>u10_4</th>\n",
       "      <th>u10_5</th>\n",
       "      <th>u10_6</th>\n",
       "      <th>u10_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v500_2_past</th>\n",
       "      <th>v500_3_past</th>\n",
       "      <th>v500_4_past</th>\n",
       "      <th>v500_5_past</th>\n",
       "      <th>v500_6_past</th>\n",
       "      <th>v500_7_past</th>\n",
       "      <th>v500_8_past</th>\n",
       "      <th>v500_13_past</th>\n",
       "      <th>v500_14_past</th>\n",
       "      <th>v500_15_past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28098</th>\n",
       "      <td>2008-12-09 02:08:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.146151</td>\n",
       "      <td>10.848257</td>\n",
       "      <td>5.385287</td>\n",
       "      <td>6.261186</td>\n",
       "      <td>0.190907</td>\n",
       "      <td>0.380253</td>\n",
       "      <td>-0.938153</td>\n",
       "      <td>6.941427</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.298292</td>\n",
       "      <td>-4.455450</td>\n",
       "      <td>1.694595</td>\n",
       "      <td>-33.181866</td>\n",
       "      <td>-35.525610</td>\n",
       "      <td>-35.092330</td>\n",
       "      <td>-31.529179</td>\n",
       "      <td>-29.741205</td>\n",
       "      <td>-13.049791</td>\n",
       "      <td>-19.230917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63850</th>\n",
       "      <td>2019-02-23 18:36:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.080545</td>\n",
       "      <td>10.669509</td>\n",
       "      <td>4.786285</td>\n",
       "      <td>1.651852</td>\n",
       "      <td>-0.309001</td>\n",
       "      <td>-4.104822</td>\n",
       "      <td>-5.957775</td>\n",
       "      <td>-6.157590</td>\n",
       "      <td>...</td>\n",
       "      <td>37.456635</td>\n",
       "      <td>31.843380</td>\n",
       "      <td>21.519958</td>\n",
       "      <td>13.360619</td>\n",
       "      <td>13.154780</td>\n",
       "      <td>13.204849</td>\n",
       "      <td>32.052925</td>\n",
       "      <td>-0.721662</td>\n",
       "      <td>27.887953</td>\n",
       "      <td>16.359177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>2006-12-12 11:06:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.843216</td>\n",
       "      <td>12.023794</td>\n",
       "      <td>3.466795</td>\n",
       "      <td>11.710372</td>\n",
       "      <td>9.169489</td>\n",
       "      <td>9.846270</td>\n",
       "      <td>10.730026</td>\n",
       "      <td>15.995771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.419672</td>\n",
       "      <td>6.579529</td>\n",
       "      <td>-3.107877</td>\n",
       "      <td>0.438633</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>2.641624</td>\n",
       "      <td>6.819158</td>\n",
       "      <td>-6.908395</td>\n",
       "      <td>-6.748642</td>\n",
       "      <td>5.188082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66730</th>\n",
       "      <td>2020-02-02 05:41:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.819938</td>\n",
       "      <td>-4.883079</td>\n",
       "      <td>-0.568672</td>\n",
       "      <td>-4.720872</td>\n",
       "      <td>11.069313</td>\n",
       "      <td>9.390392</td>\n",
       "      <td>10.015724</td>\n",
       "      <td>11.489231</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.225391</td>\n",
       "      <td>8.064178</td>\n",
       "      <td>2.862093</td>\n",
       "      <td>9.310478</td>\n",
       "      <td>20.206694</td>\n",
       "      <td>17.979542</td>\n",
       "      <td>0.770900</td>\n",
       "      <td>7.005633</td>\n",
       "      <td>23.918076</td>\n",
       "      <td>16.001648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19511</th>\n",
       "      <td>2006-07-18 22:27:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.396057</td>\n",
       "      <td>-4.546572</td>\n",
       "      <td>-2.404162</td>\n",
       "      <td>-1.505665</td>\n",
       "      <td>-2.673920</td>\n",
       "      <td>-3.262483</td>\n",
       "      <td>-1.488968</td>\n",
       "      <td>-2.701052</td>\n",
       "      <td>...</td>\n",
       "      <td>8.685511</td>\n",
       "      <td>5.925582</td>\n",
       "      <td>7.741770</td>\n",
       "      <td>12.810699</td>\n",
       "      <td>10.984708</td>\n",
       "      <td>18.689693</td>\n",
       "      <td>15.693607</td>\n",
       "      <td>11.168287</td>\n",
       "      <td>-0.210959</td>\n",
       "      <td>22.826468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  flag      u10_0      u10_1     u10_2      u10_3  \\\n",
       "28098 2008-12-09 02:08:00   1.0   5.146151  10.848257  5.385287   6.261186   \n",
       "63850 2019-02-23 18:36:00   0.0  -0.080545  10.669509  4.786285   1.651852   \n",
       "20806 2006-12-12 11:06:00   0.0  13.843216  12.023794  3.466795  11.710372   \n",
       "66730 2020-02-02 05:41:00   0.0  10.819938  -4.883079 -0.568672  -4.720872   \n",
       "19511 2006-07-18 22:27:00   0.0  -3.396057  -4.546572 -2.404162  -1.505665   \n",
       "\n",
       "           u10_4     u10_5      u10_6      u10_7  ...  v500_2_past  \\\n",
       "28098   0.190907  0.380253  -0.938153   6.941427  ...    -7.298292   \n",
       "63850  -0.309001 -4.104822  -5.957775  -6.157590  ...    37.456635   \n",
       "20806   9.169489  9.846270  10.730026  15.995771  ...     4.419672   \n",
       "66730  11.069313  9.390392  10.015724  11.489231  ...    -9.225391   \n",
       "19511  -2.673920 -3.262483  -1.488968  -2.701052  ...     8.685511   \n",
       "\n",
       "       v500_3_past  v500_4_past  v500_5_past  v500_6_past  v500_7_past  \\\n",
       "28098    -4.455450     1.694595   -33.181866   -35.525610   -35.092330   \n",
       "63850    31.843380    21.519958    13.360619    13.154780    13.204849   \n",
       "20806     6.579529    -3.107877     0.438633     0.024874     2.641624   \n",
       "66730     8.064178     2.862093     9.310478    20.206694    17.979542   \n",
       "19511     5.925582     7.741770    12.810699    10.984708    18.689693   \n",
       "\n",
       "       v500_8_past  v500_13_past  v500_14_past  v500_15_past  \n",
       "28098   -31.529179    -29.741205    -13.049791    -19.230917  \n",
       "63850    32.052925     -0.721662     27.887953     16.359177  \n",
       "20806     6.819158     -6.908395     -6.748642      5.188082  \n",
       "66730     0.770900      7.005633     23.918076     16.001648  \n",
       "19511    15.693607     11.168287     -0.210959     22.826468  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(data_path/'for_model.csv', parse_dates=['time'])\n",
    "\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2017-01-01 00:01:00 -> 2019-12-31 22:31:00. Length: 9942\n",
      "Test range: 2020-01-01 00:41:00 -> 2022-12-31 21:57:00. Length: 9561\n"
     ]
    }
   ],
   "source": [
    "# Convert \"time\" column to datetime format\n",
    "#data['time'] = pd.to_datetime(data['time'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Split the data into training and testing sets based on the date\n",
    "train_data = data[(data['time'].dt.year >= 2017) & (data['time'].dt.year <= 2019)]\n",
    "test_data = data[(data['time'].dt.year >= 2020) & (data['time'].dt.year <= 2022)]\n",
    "\n",
    "print(f\"Train range: {train_data['time'].min()} -> {train_data['time'].max()}. Length: {len(train_data)}\")\n",
    "print(f\"Test range: {test_data['time'].min()} -> {test_data['time'].max()}. Length: {len(test_data)}\")\n",
    "\n",
    "# saving the date ranges for WandB tracking\n",
    "training_date_range = \"2017-01-01 to 2019-12-31\"\n",
    "testing_date_range = \"2020-01-01 to 2022-12-31\"\n",
    "\n",
    "# Drop the \"time\" column as it won't be used in the model\n",
    "train_data = train_data.drop(columns=['time'])\n",
    "test_data = test_data.drop(columns=['time'])\n",
    "\n",
    "# Define the features (X) and the target (y)\n",
    "X_train = train_data.drop(columns=['flag'])\n",
    "y_train = train_data['flag']\n",
    "X_test = test_data.drop(columns=['flag'])\n",
    "y_test = test_data['flag']\n",
    "\n",
    "# Balanced Data - removing NaN values and associated data\n",
    "y_train = y_train.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "X_train = X_train.loc[y_train.index]\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set = 0.262\n",
      "Precision on Testing Set = 0.319\n",
      "Recall on Training Set = 0.988\n",
      "Recall on Testing Set = 0.989\n",
      "F1 Score on Training Set = 0.414\n",
      "F1 Score on Testing Set = 0.483\n"
     ]
    }
   ],
   "source": [
    "# setting up a neural network model with default parameters\n",
    "nn_model = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nn_test = nn_model.predict(X_test)\n",
    "y_pred_nn_train = nn_model.predict(X_train)\n",
    "\n",
    "# calculating scores\n",
    "precision_test = precision_score(y_test, y_pred_nn_test)\n",
    "precision_train = precision_score(y_train, y_pred_nn_train)\n",
    "recall_test = recall_score(y_test, y_pred_nn_test)\n",
    "recall_train = recall_score(y_train, y_pred_nn_train)\n",
    "f1_test = f1_score(y_test, y_pred_nn_test)\n",
    "f1_train = f1_score(y_train, y_pred_nn_train)\n",
    "\n",
    "print(f\"Precision on Training Set = {precision_train:.3f}\")\n",
    "print(f\"Precision on Testing Set = {precision_test:.3f}\")\n",
    "print(f\"Recall on Training Set = {recall_train:.3f}\")\n",
    "print(f\"Recall on Testing Set = {recall_test:.3f}\")\n",
    "print(f\"F1 Score on Training Set = {f1_train:.3f}\")\n",
    "print(f\"F1 Score on Testing Set = {f1_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "nn_classifier = MLPClassifier()\n",
    "params = nn_classifier.get_params()\n",
    "\n",
    "# printing default parameters\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'random_state': 11}\n",
      "Best F1 score: 0.560\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "# Define the model\n",
    "model = MLPClassifier(max_iter=1000, hidden_layer_sizes=(50, 50, 50), \n",
    "                         activation='relu', solver='adam', alpha=0.0001, random_state=42,\n",
    "                         learning_rate='constant', batch_size=100, early_stopping=False)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "'''\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'batch_size': [100, 200, 300],\n",
    "    'max_iter': [1000, 2000],\n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "'''\n",
    "random_states = np.linspace(0,100,101)\n",
    "random_states = random_states.astype(int)\n",
    "\n",
    "param_grid = {\n",
    "    'random_state': random_states\n",
    "}\n",
    "\n",
    "# Define the grid search\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs=-1, scoring='f1', cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_f1 = grid_search.best_score_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best F1 score: {best_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Optimised Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set = 0.469\n",
      "Precision on Testing Set = 0.556\n",
      "Recall on Training Set = 0.744\n",
      "Recall on Testing Set = 0.737\n",
      "F1 Score on Training Set = 0.575\n",
      "F1 Score on Testing Set = 0.634\n"
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"NeuralNetworks\")\n",
    "\n",
    "nn_model = MLPClassifier(max_iter=1000, hidden_layer_sizes=(50, 50, 50), \n",
    "                         activation='relu', solver='adam', alpha=0.0001, random_state=11,\n",
    "                         learning_rate='constant', batch_size=100, early_stopping=False, shuffle=False)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nn_test = nn_model.predict(X_test)\n",
    "y_pred_nn_train = nn_model.predict(X_train)\n",
    "\n",
    "# calculating scores\n",
    "precision_test = precision_score(y_test, y_pred_nn_test)\n",
    "precision_train = precision_score(y_train, y_pred_nn_train)\n",
    "recall_test = recall_score(y_test, y_pred_nn_test)\n",
    "recall_train = recall_score(y_train, y_pred_nn_train)\n",
    "f1_test = f1_score(y_test, y_pred_nn_test)\n",
    "f1_train = f1_score(y_train, y_pred_nn_train)\n",
    "\n",
    "print(f\"Precision on Training Set = {precision_train:.3f}\")\n",
    "print(f\"Precision on Testing Set = {precision_test:.3f}\")\n",
    "print(f\"Recall on Training Set = {recall_train:.3f}\")\n",
    "print(f\"Recall on Testing Set = {recall_test:.3f}\")\n",
    "print(f\"F1 Score on Training Set = {f1_train:.3f}\")\n",
    "print(f\"F1 Score on Testing Set = {f1_test:.3f}\")\n",
    "\n",
    "wandb.log({\"model_name\":\"Neural Network\", \"training_precision\":precision_train, \"testing_precision\":precision_test, \n",
    "            \"training_recall\":recall_train, \"testing_recall\":recall_test, \"training_f1\":f1_train, \"testing_f1\":f1_test,\n",
    "            \"training date range\": training_date_range, \"testing date range\": testing_date_range})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
