{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "data_path = Path.home()/'OneDrive'/'Kirstin'/'Uni'/'Year4'/'MSciProject'/'data_files'/'saved_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising WandB\n",
    "import wandb, os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"e84d2e19bd2cc42ec6e5d232cd0b6f0fe41f2189\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"NN_models.ipynb\"\n",
    "\n",
    "\n",
    "# Syntax for using WandB:\n",
    "\n",
    "# wandb.init(project=\"MSciProject\", name=\"name\", notebook=\"your-notebook-name\")\n",
    "# code here\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>flag</th>\n",
       "      <th>u10_0</th>\n",
       "      <th>u10_1</th>\n",
       "      <th>u10_2</th>\n",
       "      <th>u10_3</th>\n",
       "      <th>u10_4</th>\n",
       "      <th>u10_5</th>\n",
       "      <th>u10_6</th>\n",
       "      <th>u10_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v500_2_past</th>\n",
       "      <th>v500_3_past</th>\n",
       "      <th>v500_4_past</th>\n",
       "      <th>v500_5_past</th>\n",
       "      <th>v500_6_past</th>\n",
       "      <th>v500_7_past</th>\n",
       "      <th>v500_8_past</th>\n",
       "      <th>v500_13_past</th>\n",
       "      <th>v500_14_past</th>\n",
       "      <th>v500_15_past</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-01-02 07:50:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.852083</td>\n",
       "      <td>9.324530</td>\n",
       "      <td>1.611875</td>\n",
       "      <td>7.808569</td>\n",
       "      <td>18.997340</td>\n",
       "      <td>19.074768</td>\n",
       "      <td>17.866888</td>\n",
       "      <td>21.336483</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010510</td>\n",
       "      <td>-3.850661</td>\n",
       "      <td>-18.958298</td>\n",
       "      <td>-12.515166</td>\n",
       "      <td>-1.018695</td>\n",
       "      <td>13.810657</td>\n",
       "      <td>17.628082</td>\n",
       "      <td>-19.750593</td>\n",
       "      <td>-15.995375</td>\n",
       "      <td>16.693369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-01-02 15:52:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.592901</td>\n",
       "      <td>14.594532</td>\n",
       "      <td>0.362429</td>\n",
       "      <td>10.770398</td>\n",
       "      <td>14.584751</td>\n",
       "      <td>13.906645</td>\n",
       "      <td>10.283009</td>\n",
       "      <td>12.536574</td>\n",
       "      <td>...</td>\n",
       "      <td>17.780321</td>\n",
       "      <td>13.497995</td>\n",
       "      <td>-6.243918</td>\n",
       "      <td>1.610286</td>\n",
       "      <td>-9.154458</td>\n",
       "      <td>5.615963</td>\n",
       "      <td>22.959710</td>\n",
       "      <td>-21.638025</td>\n",
       "      <td>-12.137025</td>\n",
       "      <td>-1.259330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-01-04 16:37:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.714251</td>\n",
       "      <td>10.323761</td>\n",
       "      <td>1.472504</td>\n",
       "      <td>15.925480</td>\n",
       "      <td>20.108229</td>\n",
       "      <td>18.527065</td>\n",
       "      <td>14.082691</td>\n",
       "      <td>16.077892</td>\n",
       "      <td>...</td>\n",
       "      <td>16.608246</td>\n",
       "      <td>8.840803</td>\n",
       "      <td>3.836572</td>\n",
       "      <td>-9.439291</td>\n",
       "      <td>-40.350285</td>\n",
       "      <td>-2.100735</td>\n",
       "      <td>1.187947</td>\n",
       "      <td>-20.215494</td>\n",
       "      <td>-7.206458</td>\n",
       "      <td>-8.547140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-01-04 20:38:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.595257</td>\n",
       "      <td>9.802139</td>\n",
       "      <td>1.850679</td>\n",
       "      <td>13.439630</td>\n",
       "      <td>17.742190</td>\n",
       "      <td>14.301935</td>\n",
       "      <td>15.184616</td>\n",
       "      <td>11.609882</td>\n",
       "      <td>...</td>\n",
       "      <td>11.294628</td>\n",
       "      <td>-0.735498</td>\n",
       "      <td>-11.130286</td>\n",
       "      <td>-38.631460</td>\n",
       "      <td>-19.680204</td>\n",
       "      <td>-11.981513</td>\n",
       "      <td>-1.061256</td>\n",
       "      <td>-15.533747</td>\n",
       "      <td>-6.545120</td>\n",
       "      <td>-23.261904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-05 00:39:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.671734</td>\n",
       "      <td>7.063629</td>\n",
       "      <td>1.205173</td>\n",
       "      <td>11.726432</td>\n",
       "      <td>13.065531</td>\n",
       "      <td>16.226229</td>\n",
       "      <td>17.666391</td>\n",
       "      <td>3.238680</td>\n",
       "      <td>...</td>\n",
       "      <td>6.038302</td>\n",
       "      <td>-3.164769</td>\n",
       "      <td>-24.450348</td>\n",
       "      <td>-10.958404</td>\n",
       "      <td>-2.891393</td>\n",
       "      <td>10.613646</td>\n",
       "      <td>4.468444</td>\n",
       "      <td>-15.044292</td>\n",
       "      <td>-1.735689</td>\n",
       "      <td>20.713780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  flag      u10_0      u10_1     u10_2      u10_3  \\\n",
       "0 1998-01-02 07:50:00   1.0  14.852083   9.324530  1.611875   7.808569   \n",
       "1 1998-01-02 15:52:00   0.0  14.592901  14.594532  0.362429  10.770398   \n",
       "2 1998-01-04 16:37:00   1.0  12.714251  10.323761  1.472504  15.925480   \n",
       "3 1998-01-04 20:38:00   1.0  12.595257   9.802139  1.850679  13.439630   \n",
       "4 1998-01-05 00:39:00   1.0   9.671734   7.063629  1.205173  11.726432   \n",
       "\n",
       "       u10_4      u10_5      u10_6      u10_7  ...  v500_2_past  v500_3_past  \\\n",
       "0  18.997340  19.074768  17.866888  21.336483  ...    -1.010510    -3.850661   \n",
       "1  14.584751  13.906645  10.283009  12.536574  ...    17.780321    13.497995   \n",
       "2  20.108229  18.527065  14.082691  16.077892  ...    16.608246     8.840803   \n",
       "3  17.742190  14.301935  15.184616  11.609882  ...    11.294628    -0.735498   \n",
       "4  13.065531  16.226229  17.666391   3.238680  ...     6.038302    -3.164769   \n",
       "\n",
       "   v500_4_past  v500_5_past  v500_6_past  v500_7_past  v500_8_past  \\\n",
       "0   -18.958298   -12.515166    -1.018695    13.810657    17.628082   \n",
       "1    -6.243918     1.610286    -9.154458     5.615963    22.959710   \n",
       "2     3.836572    -9.439291   -40.350285    -2.100735     1.187947   \n",
       "3   -11.130286   -38.631460   -19.680204   -11.981513    -1.061256   \n",
       "4   -24.450348   -10.958404    -2.891393    10.613646     4.468444   \n",
       "\n",
       "   v500_13_past  v500_14_past  v500_15_past  \n",
       "0    -19.750593    -15.995375     16.693369  \n",
       "1    -21.638025    -12.137025     -1.259330  \n",
       "2    -20.215494     -7.206458     -8.547140  \n",
       "3    -15.533747     -6.545120    -23.261904  \n",
       "4    -15.044292     -1.735689     20.713780  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(data_path/'for_model.csv', parse_dates=['time'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2016-01-01 02:09:00 -> 2018-12-31 16:10:00. Length: 3118\n",
      "Val range: 2019-01-01 13:50:00 -> 2019-12-29 18:29:00. Length: 642\n",
      "Test range: 2020-01-03 00:50:00 -> 2022-12-31 08:37:00. Length: 2978\n"
     ]
    }
   ],
   "source": [
    "# Convert \"time\" column to datetime format\n",
    "#data['time'] = pd.to_datetime(data['time'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Split the data into training and testing sets based on the date\n",
    "train_data = data[(data['time'].dt.year >= 2016) & (data['time'].dt.year <= 2018)]\n",
    "val_data = data[(data['time'].dt.year >= 2019) & (data['time'].dt.year <= 2019)]\n",
    "test_data = data[(data['time'].dt.year >= 2020) & (data['time'].dt.year <= 2023)]\n",
    "\n",
    "print(f\"Train range: {train_data['time'].min()} -> {train_data['time'].max()}. Length: {len(train_data)}\")\n",
    "print(f\"Val range: {val_data['time'].min()} -> {val_data['time'].max()}. Length: {len(val_data)}\")\n",
    "print(f\"Test range: {test_data['time'].min()} -> {test_data['time'].max()}. Length: {len(test_data)}\")\n",
    "\n",
    "# saving the date ranges for WandB tracking\n",
    "# training_date_range = \"2016\"\n",
    "# validation_date_range = \"2020-01-01 to 2020-12-31\"\n",
    "# testing_date_range = \"2020-01-01 to 2022-12-31\"\n",
    "\n",
    "# Drop the \"time\" column as it won't be used in the model\n",
    "train_data = train_data.drop(columns=['time'])\n",
    "val_data = val_data.drop(columns=['time'])\n",
    "test_data = test_data.drop(columns=['time'])\n",
    "\n",
    "# Define the features (X) and the target (y)\n",
    "X_train = train_data.drop(columns=['flag'])\n",
    "y_train = train_data['flag']\n",
    "X_val = val_data.drop(columns=['flag'])\n",
    "y_val = val_data['flag']\n",
    "X_test = test_data.drop(columns=['flag'])\n",
    "y_test = test_data['flag']\n",
    "\n",
    "# Balanced Data - removing NaN values and associated data\n",
    "y_train = y_train.dropna()\n",
    "y_val = y_val.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "X_train = X_train.loc[y_train.index]\n",
    "X_val = X_val.loc[y_val.index]\n",
    "X_test = X_test.loc[y_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN model with original parameters, evaluating based on performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set = 0.907\n",
      "Precision on Validation Set = 0.870\n",
      "Recall on Training Set = 0.918\n",
      "Recall on Validation Set = 0.874\n",
      "F1 Score on Training Set = 0.913\n",
      "F1 Score on Validation Set = 0.872\n"
     ]
    }
   ],
   "source": [
    "# setting up a neural network model with default parameters\n",
    "nn_model = MLPClassifier(max_iter=1000, random_state=42)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_val = nn_model.predict(X_val)\n",
    "y_pred_train = nn_model.predict(X_train)\n",
    "\n",
    "# calculating scores\n",
    "precision_val = precision_score(y_val, y_pred_val)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_val = recall_score(y_val, y_pred_val)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "f1_val = f1_score(y_val, y_pred_val)\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Precision on Training Set = {precision_train:.3f}\")\n",
    "print(f\"Precision on Validation Set = {precision_val:.3f}\")\n",
    "print(f\"Recall on Training Set = {recall_train:.3f}\")\n",
    "print(f\"Recall on Validation Set = {recall_val:.3f}\")\n",
    "print(f\"F1 Score on Training Set = {f1_train:.3f}\")\n",
    "print(f\"F1 Score on Validation Set = {f1_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'activation': 'relu', 'alpha': 0.05, 'batch_size': 100, 'early_stopping': True, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 1000, 'solver': 'adam'}\n",
      "Best F1 score: 0.898\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42)\n",
    "\n",
    "# hyperparameters to explore\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'batch_size': [100, 200, 300],\n",
    "    'max_iter': [1000, 2000],\n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs=-1, scoring='f1', cv=5)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# extracting best parameters and score\n",
    "results = grid_search.best_estimator_\n",
    "\n",
    "validation_f1 = results.score(X_val, y_val)\n",
    "\n",
    "print(f'Validation F1 Score: {validation_f1:.3f}')\n",
    "print(f'Best Parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Optimised Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Training Set = 0.883\n",
      "Precision on Testing Set = 0.833\n",
      "Recall on Training Set = 0.962\n",
      "Recall on Testing Set = 0.932\n",
      "F1 Score on Training Set = 0.921\n",
      "F1 Score on Testing Set = 0.880\n"
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"NeuralNetworks\")\n",
    "\n",
    "nn_model = MLPClassifier(random_state=42,\n",
    "                         max_iter=1000, \n",
    "                         hidden_layer_sizes=(100,), \n",
    "                         shuffle=False,\n",
    "                         activation='relu', \n",
    "                         solver='adam', \n",
    "                         alpha=0.05, \n",
    "                         learning_rate='constant', \n",
    "                         batch_size=100, \n",
    "                         early_stopping=True,\n",
    "                         learning_rate_init=0.001,\n",
    "                         beta_2=0.9,)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_val = nn_model.predict(X_val)\n",
    "y_pred_train = nn_model.predict(X_train)\n",
    "\n",
    "# calculating scores\n",
    "precision_val = precision_score(y_val, y_pred_val)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_val = recall_score(y_val, y_pred_val)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "f1_val = f1_score(y_val, y_pred_val)\n",
    "f1_train = f1_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Precision on Training Set = {precision_train:.3f}\")\n",
    "print(f\"Precision on Testing Set = {precision_val:.3f}\")\n",
    "print(f\"Recall on Training Set = {recall_train:.3f}\")\n",
    "print(f\"Recall on Testing Set = {recall_val:.3f}\")\n",
    "print(f\"F1 Score on Training Set = {f1_train:.3f}\")\n",
    "print(f\"F1 Score on Testing Set = {f1_val:.3f}\")\n",
    "\n",
    "# wandb.log({\"model_name\":\"Neural Network\", \"training_precision\":precision_train, \"testing_precision\":precision_test, \n",
    "            # \"training_recall\":recall_train, \"testing_recall\":recall_test, \"training_f1\":f1_train, \"testing_f1\":f1_test,\n",
    "            # \"training date range\": training_date_range, \"testing date range\": testing_date_range})\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Testing Set = 0.891\n",
      "Recall on Testing Set = 0.954\n",
      "F1 Score on Testing Set = 0.921\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = nn_model.predict(X_test)\n",
    "\n",
    "precision_test = precision_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Precision on Testing Set = {precision_test:.3f}\")\n",
    "print(f\"Recall on Testing Set = {recall_test:.3f}\")\n",
    "print(f\"F1 Score on Testing Set = {f1_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\kirst\\\\OneDrive\\\\Kirstin\\\\Uni\\\\Year4\\\\MSciProject\\\\data_files\\\\saved_files\\\\nn_model.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "dump(nn_model, data_path/'nn_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
